















































import math
import os
import sys
import warnings
from datetime import datetime
from pathlib import Path
import seaborn as sns
from scipy import stats
import matplotlib.pyplot as plt
import itables
import itables.options as opt
import joblib
import numpy as np
import pandas as pd
import yaml
from ydata_profiling import ProfileReport

# jupyer notebook libraries
opt.columnDefs = [
    {"className": "dt-center", "targets": "_all"}
]  # Center-align all columns
opt.maxBytes = 0  # Display full content, no truncation
# Configure itables to display DataFrames automatically
itables.init_notebook_mode(all_interactive=True)
print_df_chars = True
get_ipython().run_line_magic("matplotlib", " inline")





def identify_binary_variables(df):
    """
    Identifies binary variables in a DataFrame.

    Args:
        df (pd.DataFrame): The input DataFrame.

    Returns:
        list: A list of binary variable column names.
    """
    binary_columns = []

    for col in df.columns:
        unique_values = df[col].dropna().unique()
        if len(unique_values) == 2:
            binary_columns.append(col)

    print(f"Binary Variables Detected: {binary_columns}")
    return binary_columns


def eda_on_date_column(df, date_column):
    """
    Perform EDA on a date column: min, max, and frequency by month.

    Args:
        df (pd.DataFrame): The input DataFrame.
        date_column (str): The name of the date column.

    Returns:
        None
    """
    # Ensure the date column is in datetime format
    df[date_column] = pd.to_datetime(df[date_column], errors="coerce")

    # Drop rows where date conversion failed
    df = df.dropna(subset=[date_column])

    # Get the minimum and maximum dates
    min_date = df[date_column].min()
    max_date = df[date_column].max()

    print(f"Minimum Date in '{date_column}': {min_date}")
    print(f"Maximum Date in '{date_column}': {max_date}")

    # Frequency of records per month
    monthly_freq = df[date_column].dt.to_period("M").value_counts().sort_index()

    # Plotting frequency per month
    plt.figure(figsize=(12, 6))
    monthly_freq.plot(kind="bar", color="skyblue")
    plt.title(f"Frequency of Records per Month ({date_column})")
    plt.xlabel("Month")
    plt.ylabel("Number of Records")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()


def detect_outliers_iqr(df, columns):
    """
    Detects outliers in specified columns of a DataFrame using the IQR method.

    Args:
        df (pd.DataFrame): The input DataFrame.
        columns (list): List of columns to check for outliers.

    Returns:
        dict: A dictionary with column names as keys and lists of outlier indices as values.
    """
    outliers = {}

    for col in columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1

            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            outlier_indices = df[
                (df[col] < lower_bound) | (df[col] > upper_bound)
            ].index.tolist()
            outliers[col] = outlier_indices

            print(f"Outliers detected in '{col}': {len(outlier_indices)}")

    return outliers


def detect_outliers_zscore(df, columns, threshold=3):
    """
    Detects outliers in specified columns of a DataFrame using the Z-score method.

    Args:
        df (pd.DataFrame): The input DataFrame.
        columns (list): List of columns to check for outliers.
        threshold (float): Z-score threshold to identify outliers (default = 3).

    Returns:
        dict: A dictionary with column names as keys and lists of outlier indices as values.
    """
    outliers = {}

    for col in columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            z_scores = np.abs(stats.zscore(df[col].dropna()))
            outlier_indices = df[(z_scores > threshold)].index.tolist()
            outliers[col] = outlier_indices

            print(f"Outliers detected in '{col}': {len(outlier_indices)}")

    return outliers

# Function to detect outliers using IQR and plot
def detect_outliers_iqr(df, columns):
    """
    Detects outliers in specified columns of a DataFrame using the IQR method and plots them in red.

    Args:
        df (pd.DataFrame): The input DataFrame.
        columns (list): List of columns to check for outliers.

    Returns:
        dict: A dictionary with column names as keys and lists of outlier indices as values.
    """
    outliers = {}

    for col in columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1

            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            outlier_indices = df[
                (df[col] < lower_bound) | (df[col] > upper_bound)
            ].index.tolist()
            outliers[col] = outlier_indices

            print(f"Outliers detected in '{col}': {len(outlier_indices)}")

            # Plotting with outliers highlighted in red
            plt.figure(figsize=(8, 5))
            sns.boxplot(x=df[col], color="skyblue", width=0.5)

            # Highlight outliers in red
            outlier_values = df.loc[outlier_indices, col]
            plt.scatter(
                outlier_values,
                [0] * len(outlier_values),
                color="red",
                s=100,
                label="Outlier",
            )

            plt.title(f"{col} with Outliers Highlighted (IQR)")
            plt.xlabel(col)
            plt.legend(["Outlier"], loc="upper right")
            plt.show()

    return outliers


# Function to detect outliers using Z-score and plot
def detect_outliers_zscore(df, columns, threshold=3):
    """
    Detects outliers in specified columns of a DataFrame using the Z-score method and plots them in red.

    Args:
        df (pd.DataFrame): The input DataFrame.
        columns (list): List of columns to check for outliers.
        threshold (float): Z-score threshold to identify outliers (default = 3).

    Returns:
        dict: A dictionary with column names as keys and lists of outlier indices as values.
    """
    outliers = {}

    for col in columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            z_scores = np.abs(stats.zscore(df[col].dropna()))
            outlier_indices = df[z_scores > threshold].index.tolist()
            outliers[col] = outlier_indices

            print(f"Outliers detected in '{col}': {len(outlier_indices)}")

            # Plotting with outliers highlighted in red
            plt.figure(figsize=(8, 5))
            sns.boxplot(x=df[col], color="lightgreen", width=0.5)

            # Highlight outliers in red
            outlier_values = df.loc[outlier_indices, col]
            plt.scatter(
                outlier_values,
                [0] * len(outlier_values),
                color="red",
                s=100,
                label="Outlier",
            )

            plt.title(f"{col} with Outliers Highlighted (Z-Score)")
            plt.xlabel(col)
            plt.legend(["Outlier"], loc="upper right")
            plt.show()

    return outliers

def count_id_occurrences(df, id_column, count_column_name="id_count"):
    """
    Adds a new column that counts the number of times each ID appears in the dataset.

    Args:
        df (pd.DataFrame): The input DataFrame.
        id_column (str): The name of the ID column.
        count_column_name (str): The name of the new column with count values (default: 'id_count').

    Returns:
        pd.DataFrame: The DataFrame with the new count column added.
    """
    if id_column not in df.columns:
        raise ValueError(f"Column '{id_column}' not found in DataFrame.")

    # Count occurrences of each ID
    id_counts = df[id_column].value_counts().to_dict()

    # Map counts back to the DataFrame
    df[count_column_name] = df[id_column].map(id_counts)

    return df

def check_and_identify_problematic_columns(df: pd.DataFrame) -> tuple:
    """Checks for NaN and Inf values, prints problematic columns, and identifies columns to drop.

    Args:
        df: The input Pandas DataFrame.

    Returns:
        A tuple containing:
            - A list of columns containing NaN values that are in the nan_columns_to_drop list.
            - A list of columns containing Inf values that are in the inf_columns_to_drop list.
            - A list of unique columns that are either in nan_cols_to_drop or inf_cols_to_drop
              (or both). This represents the combined set of columns that *could* be dropped.
            - The original DataFrame (unchanged).
    """

    nan_columns_found = df.columns[df.isna().any()].tolist()
    inf_columns_found = df.columns[np.isinf(df).any()].tolist()

    print("Columns containing NaN values:", nan_columns_found)
    print("Columns containing Inf values:", inf_columns_found)

    nan_columns_to_drop = ['metric_per_day', 'turnover_sum_per_day', 'turnover_num_per_day',
                           'NGR_sum_per_day', 'deposit_sum_per_day', 'deposit_num_per_day',
                           'withdrawal_sum_per_day', 'withdrawal_num_per_day']

    inf_columns_to_drop = ['metric_per_day', 'turnover_sum_per_day', 'turnover_num_per_day',
                           'NGR_sum_per_day', 'deposit_sum_per_day', 'deposit_num_per_day',
                           'withdrawal_sum_per_day', 'withdrawal_num_per_day', 'login_num_per_day']

    nan_cols_to_drop = list(set(nan_columns_to_drop) & set(nan_columns_found))
    inf_cols_to_drop = list(set(inf_columns_to_drop) & set(inf_columns_found))

    combined_cols_to_drop = list(set(nan_cols_to_drop) | set(inf_cols_to_drop))  # Unique combined list

    return nan_cols_to_drop, inf_cols_to_drop, combined_cols_to_drop, df  # Return the lists and the original DataFrame


def EDA(df: pd.DataFrame, columns_to_check: list):
    """Performs Exploratory Data Analysis (EDA) on a Pandas DataFrame.

    Generates an interactive table, a profiling report, identifies binary variables,
    performs EDA on a date column, and detects outliers using IQR and Z-score methods.

    Args:
        df: The input Pandas DataFrame.
        columns_to_check: A list of column names to check for outliers.
    """
    itables.show(df.head(100))  # Display the DataFrame interactively

    # Generate EDA Report
    profile_al = ProfileReport(
        df, title="Churn Data EDA", explorative=True, samples=None
    )  # samples=None for all rows

    # Display the report in Jupyter
    profile_al.to_notebook_iframe()

    binary_vars = identify_binary_variables(df)  # Identify binary variables
    print(f"\nBinary Variables: {binary_vars}")


    eda_on_date_column(df, "date")  # Perform EDA on the 'date' column

    nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)

    # Detect outliers using IQR
    # print("\nDetect outliers using IQR:")
    # iqr_outliers = detect_outliers_iqr(df, columns_to_check)

    # Detect outliers using Z-score
    # print("\nDetect outliers using Z-score:")
    #zscore_outliers = detect_outliers_zscore(df, columns_to_check)

    # df = count_id_occurrences(df, id_column="player_key")  # Count ID occurrences






import pandas as pd
from typing import Optional

import pandas as pd
from typing import Optional

def read_csv(
    file_path: str,
    sep: str = ",",
    header: int = 0,
    index_col: Optional[str] = None,
    usecols: Optional[list[str]] = None,
    dtype: Optional[dict] = None,
    names: Optional[list] = None,
    skiprows: Optional[int] = None,
    nrows: Optional[int] = None,
    na_values: Optional[list] = None,
    parse_dates: Optional[list] = None,
    encoding: str = "utf-8",
    # date_parser: callable = None,  <- Remove this deprecated argument
    low_memory: bool = True,
    skip_blank_lines: bool = True,
    thousands: Optional[str] = None,
    comment: Optional[str] = None,
    date_format: Optional[str] = None #<- Add date_format parameter
) -> pd.DataFrame:
    """
    Read data from a CSV file and return as a DataFrame.
    """
    try:
        if date_format: # If date_format is provided, use it.
            data = pd.read_csv(
                file_path,
                sep=sep,
                header=header,
                index_col=index_col,
                usecols=usecols,
                dtype=dtype,
                names=names,
                skiprows=skiprows,
                nrows=nrows,
                na_values=na_values,
                parse_dates=parse_dates,
                encoding=encoding,
                low_memory=low_memory,
                skip_blank_lines=skip_blank_lines,
                thousands=thousands,
                comment=comment,
            )
        else: # If date_format is not provided, try to infer, if parse_dates is given.
            data = pd.read_csv(
                file_path,
                sep=sep,
                header=header,
                index_col=index_col,
                usecols=usecols,
                dtype=dtype,
                names=names,
                skiprows=skiprows,
                nrows=nrows,
                na_values=na_values,
                parse_dates=parse_dates,
                encoding=encoding,
                low_memory=low_memory,
                skip_blank_lines=skip_blank_lines,
                thousands=thousands,
                comment=comment,
            )

        print(f"Data extracted successfully from {file_path}")
        return data
    except Exception as e:
        print(f"Error reading CSV file {file_path}: {e}")
        raise

def print_df_characteristics(df, print_=True):
    if print_ == True:
        print(f"Columns: {df.columns}")
        print(f"DTypes: {df.dtypes}")
        print(f"Shape of df: {df.shape}")
        itables.show(df.head(10))

        
def ETL(raw_data_path, processed_data_path):
    """
    Extract, transform, and load (ETL) the data.

    Args:
        - config (dict): The configuration dictionary containing the ETL paths.

    Returns:
        - data (pandas DataFrame): The loaded and processed data.
    """

    data = read_csv(raw_data_path)
    # data = data.head(1000)  # Example: limit to 1000 rows for testing
    path_processed_data_path = Path(processed_data_path)

    # Check if the file exists before saving
    path_processed_data_path.parent.mkdir(parents=True, exist_ok=True)

    # Load (save) only if file does not exist
    if not path_processed_data_path.exists():
        joblib.dump(data, processed_data_path)
        print(f"Data saved to {processed_data_path}")
    else:
        print(f"File already exists at {processed_data_path}. No new data saved.")

    print(f"Columns: {data.columns}")
    print(f"DTypes: {data.dtypes}")
    print(f"Shape of df: {data.shape}")
    return data





df = ETL(raw_data_path="./data/raw_data/data.csv", processed_data_path="./data/processed/etl_data.pkl")
itables.show(df.head(100))






# Define the columns for outlier detection
columns_to_check = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
    "duration"
]
EDA(df, columns_to_check)







def read_pickle(file_path: str) -> pd.DataFrame:
    """Reads data from a pickle file and returns a Pandas DataFrame.

    Args:
        file_path (str): The path to the pickle file.

    Returns:
        pd.DataFrame: A Pandas DataFrame containing the data from the pickle file.
        Returns an empty DataFrame if there's an error.
    """
    try:
        df = joblib.load(file_path)
        print(f"Data successfully read from {file_path}")
        return df
    except FileNotFoundError:
        print(f"Error: Pickle file not found at {file_path}")
        return pd.DataFrame()  # Return an empty DataFrame
    except Exception as e:  # Catch other potential errors (e.g., corrupted file)
        print(f"Error reading pickle file {file_path}: {e}")
        return pd.DataFrame()  # Return an empty DataFrame

def convert_columns_to_datetime(df, columns):
    """
    Converts specified columns in a DataFrame from string to datetime format automatically.

    Args:
        df (pd.DataFrame): The input DataFrame.
        columns (list): List of column names to be converted.

    Returns:
        pd.DataFrame: DataFrame with specified columns converted to datetime where applicable.
    """
    for col in columns:
        try:
            # Attempt conversion without infer_datetime_format
            converted_col = pd.to_datetime(df[col], errors="coerce")

            # Check if conversion was successful (less than 50% NaT after conversion)
            if converted_col.notna().sum() / len(df) > 0.5:
                df[col] = converted_col
                print(f"Column '{col}' successfully converted to datetime.")
            else:
                print(
                    f"Column '{col}' could not be reliably converted to datetime. Skipping."
                )

        except Exception as e:
            print(f"Error converting column '{col}': {e}")

    return df


def convert_birth_year_to_datetime(df, column_name="birth_year"):
    """
    Converts a column representing birth years (as integers) to datetime.

    Args:
        df (pd.DataFrame): The input DataFrame.
        column_name (str): The name of the column containing birth years.

    Returns:
        pd.DataFrame: DataFrame with the birth year column converted to datetime.
    """
    if column_name in df.columns:
        try:
            # Convert the integer year to a datetime, defaulting to January 1st of that year
            df[column_name] = pd.to_datetime(
                df[column_name], format="%Y", errors="coerce"
            )
            print(f"Column '{column_name}' successfully converted to datetime.")
        except Exception as e:
            print(f"Error converting column '{column_name}': {e}")
    else:
        print(f"Column '{column_name}' not found in DataFrame.")

    return df


def calculate_age(df, birth_date_column="birth_year", age_column="age"):
    """
    Calculates age from a datetime birth year column and adds it to the DataFrame.

    Args:
        df (pd.DataFrame): The input DataFrame.
        birth_date_column (str): The name of the column with birth dates (in datetime format).
        age_column (str): The name of the column to store the calculated age.

    Returns:
        pd.DataFrame: DataFrame with an additional 'age' column.
    """
    if birth_date_column in df.columns:
        try:
            # Get the current date
            today = pd.Timestamp(datetime.today().date())

            # Calculate the age
            df[age_column] = df[birth_date_column].apply(
                lambda birth_date: math.ceil(
                    (today.year - birth_date.year)
                    - ((today.month, today.day) < (birth_date.month, birth_date.day))
                )
            )

            print(f"Age successfully calculated and stored in '{age_column}'.")
        except Exception as e:
            print(f"Error calculating age from column '{birth_date_column}': {e}")
    else:
        print(f"Column '{birth_date_column}' not found in DataFrame.")

    return df





# read the ETL data saved after loading the data
df = read_pickle(file_path="./data/processed/etl_data.pkl")

df = convert_columns_to_datetime(df, columns=["date"]) # Convert date column to datetime
df = convert_birth_year_to_datetime(df, column_name="birth_year") # Convert birth_year column to datetime
df = calculate_age(df, birth_date_column="birth_year", age_column="age") # calculate the age
print_df_characteristics(df, print_=print_df_chars)


def add_row_number_within_player(df, player_id_col="player_key", date_col="date"):
    """Adds a row number within each player group, ordered by date.

    Args:
        df: Pandas DataFrame with player_id and date columns.
        player_id_col: Name of the player ID column.
        date_col: Name of the date column.

    Returns:
        Pandas DataFrame with the added 'row_number' column.
        Returns the original DataFrame if any error occurs.
    """
    try:
        df[date_col] = pd.to_datetime(df[date_col])  # Ensure date is datetime
        df = df.sort_values([player_id_col, date_col])  # Sort by player and date
        df = df.set_index(pd.RangeIndex(start=0, stop=len(df)))

        df["row_number"] = (
            df.groupby(player_id_col).cumcount() + 1
        )  # Efficiently add row numbers
        df['max_row_number'] = df.groupby('player_key')['row_number'].transform('max')

        return df

    except (KeyError, TypeError) as e:
        print(f"Error adding row number: {e}")
        return df




df = add_row_number_within_player(df, player_id_col="player_key", date_col="date") # add an increasing number for each activity of the player_key chronologacally
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)



def convert_int_to_float(df, exclude_columns=None):
    """
    Converts integer columns in a DataFrame to float, excluding specified columns.

    Args:
        df (pd.DataFrame): The input DataFrame.
        exclude_columns (list, optional): List of column names to exclude from conversion.
                                          Default is None, meaning no exclusions.

    Returns:
        pd.DataFrame: DataFrame with integer columns converted to float, excluding specified columns.
    """
    if exclude_columns is None:
        exclude_columns = []

    # Automatically detect integer columns, excluding specified ones
    int_columns = [
        col
        for col in df.select_dtypes(include=["int64", "int32"]).columns
        if col not in exclude_columns
    ]

    for col in int_columns:
        df[col] = df[col].astype(float)
        print(f"Column '{col}' converted to float.")

    return df


df = convert_int_to_float(df, exclude_columns=["player_key"]) # convert integers to float(will repeat that later also before training the model
print_df_characteristics(df, print_=print_df_chars)


def add_date_range_columns(df, date_column, id_column):
    """
    Adds four columns to the DataFrame:
    - 'start_date': Minimum date for each ID
    - 'end_date': Maximum date for each ID
    - 'max_date': The overall maximum date (constant for all rows)
    - 'min_date': The overall minimum date (constant for all rows)

    Args:
        df (pd.DataFrame): The input DataFrame.
        date_column (str): The name of the date column.
        id_column (str): The name of the ID column.

    Returns:
        pd.DataFrame: The updated DataFrame with four new columns.
    """
    if date_column not in df.columns or id_column not in df.columns:
        raise ValueError(
            f"Columns '{date_column}' or '{id_column}' not found in DataFrame."
        )

    # Convert to datetime if not already
    df[date_column] = pd.to_datetime(df[date_column], errors="coerce")

    # Compute start and end dates per ID
    df["start_date"] = df.groupby(id_column)[date_column].transform("min")
    df["end_date"] = df.groupby(id_column)[date_column].transform("max")

    # Compute global min/max dates
    min_date = df[date_column].min()
    max_date = df[date_column].max()

    df["min_date"] = min_date
    df["max_date"] = max_date

    return df


df = add_date_range_columns(df, date_column="date", id_column="player_key") # create min and max date for each player_key
df = df.sort_values(by=["player_key", "date"])
print_df_characteristics(df, print_=print_df_chars)


# Calculate the duration of activity for each player
import pandas as pd


def calculate_duration(
    df, start_date_col="start_date", end_date_col="end_date", duration_col="duration"
):
    """
    Calculates the duration (difference in days) between end_date and start_date.

    Args:
        df (pd.DataFrame): The input DataFrame.
        start_date_col (str): The name of the column with the start date.
        end_date_col (str): The name of the column with the end date.
        duration_col (str): The name of the new column to store the duration.

    Returns:
        pd.DataFrame: The updated DataFrame with the 'duration' column added.
    """
    if start_date_col not in df.columns or end_date_col not in df.columns:
        raise ValueError(
            f"Columns '{start_date_col}' or '{end_date_col}' not found in DataFrame."
        )

    # Convert to datetime if not already
    df[start_date_col] = pd.to_datetime(df[start_date_col], errors="coerce")
    df[end_date_col] = pd.to_datetime(df[end_date_col], errors="coerce")

    # Calculate duration in days
    df[duration_col] = (df[end_date_col] - df[start_date_col]).dt.days

    return df


df = calculate_duration(df, start_date_col="start_date", end_date_col="end_date", duration_col="duration_all") # Calculate the duration of activity for each player
df = calculate_duration(df, start_date_col="start_date", end_date_col="date", duration_col="duration_spot") # Calculate the duration of activity for each player

print_df_characteristics(df, print_=print_df_chars)


# Calculate churn
import pandas as pd


def create_churn_column(
    df, end_date_col="end_date", max_date_col="max_date", churn_days=30
):
    """
    Creates a 'churn' column based on the difference between end_date and max_date.

    Args:
        df: Pandas DataFrame containing the end_date and max_date columns.
        end_date_col: Name of the column containing the end date (datetime).
        max_date_col: Name of the column containing the maximum date (datetime).
        churn_days: Number of days of inactivity to define churn.

    Returns:
        Pandas DataFrame with the added 'churn' column.
        Returns the original DataFrame if there are any errors during processing.
    """

    try:
        # Ensure date columns are datetime objects
        df[end_date_col] = pd.to_datetime(df[end_date_col])
        df[max_date_col] = pd.to_datetime(df[max_date_col])

        # Calculate the difference in days
        df["date_difference"] = (df[max_date_col] - df[end_date_col]).dt.days

        # Create the churn column
        df["churn"] = (df["max_row_number"] == df["row_number"]).astype(int)

        # Drop the temporary date_difference column (optional, but good practice)
        df = df.drop("date_difference", axis=1)

        return df

    except (KeyError, TypeError) as e:  # Handle potential errors gracefully
        print(f"Error creating churn column: {e}")
        return df  # Return original DataFrame if error occurs


df = create_churn_column(
    df, end_date_col="end_date", max_date_col="max_date", churn_days=30
)
print_df_characteristics(df, print_=print_df_chars)



def drop_rows_with_negative_values(df: pd.DataFrame, columns: list) -> pd.DataFrame:
    """Drops rows from a DataFrame where any of the specified columns have values below zero.

    Args:
        df: The input Pandas DataFrame.
        columns: A list of column names to check for negative values.

    Returns:
        A new Pandas DataFrame with the rows containing negative values in the specified
        columns removed.  Also prints the number of rows deleted. Returns the original DataFrame if no specified columns are found
        or if no negative values are found.
    """

    if not columns or not all(col in df.columns for col in columns):  # Check if columns exist
        print("One or more of the specified columns were not found in the dataframe")
        return df  # Return original dataframe

    original_rows = len(df)  # Store the original number of rows
    df_filtered = df.copy()  # Create a copy

    for col in columns:
        df_filtered = df_filtered[df_filtered[col] >= 0]

    rows_deleted = original_rows - len(df_filtered)  # Calculate the number of deleted rows
    print(f"Number of rows deleted: {rows_deleted}")  # Print the count

    return df_filtered


delete_negatives_columns = [
    "turnover_sum",
    "turnover_num",
    #"NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
    'age', 
    #'start_date', 'end_date', 'min_date', 'max_date', 
    'duration_all',
    'duration_spot',
    'churn'
]
df = drop_rows_with_negative_values(df, delete_negatives_columns) # delete the rows where any of the above coluns is negative







# Define the columns for outlier detection
columns_to_check = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
    'age', 'start_date', 'end_date',
       'min_date', 'max_date', 
        'duration_spot',
    'duration_all', 'churn'
]
EDA(df, columns_to_check)






joblib.dump(df, "./data/processed/data_prep.pkl")











### read data preparation data
df = joblib.load("./data/processed/data_prep.pkl")


# metrics to be used to create features
metrics_cols = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
    "time_between_interactions",
    'duration_spot',
]





df['player_key_backup'] = df['player_key']
df['player_key'] = df['player_key'].rank(method='dense').astype(int) #method='dense' is important as you want consecutive ranking



# calculate the time between the datapoints for each user
def compute_time_between_interactions(df, key_id="player_key", date="date"):
    """
    Computes the time difference (in minutes) between consecutive bets for each player.
    If a player has no previous bet, assigns -1.

    Args:
        df (pd.DataFrame): Input DataFrame with 'player_key' and 'date'.

    Returns:
        pd.DataFrame: DataFrame with a new column 'time_between_bets'.
    """
    # Ensure 'date' is in datetime format
    df['date'] = pd.to_datetime(df['date'])

    # Sort values by player and date
    df = df.sort_values(by=['player_key', 'date'])

    # Compute time difference in minutes
    df['time_between_interactions'] = df.groupby('player_key')['date'].diff().dt.days

    # Fill NaN (first bet) with -1
    df['time_between_interactions'] = df['time_between_interactions'].fillna(0).astype(int)

    return df



df = compute_time_between_interactions(df, key_id="player_key", date="date")
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)


def calculate_cumulative_metrics(
    df,
    key_col="player_key",
    date_col="date",
    start_date_col="start_date",
    end_date_col="end_date",
    metrics=None,
):
    """Calculates cumulative sums of metrics from start_date to each date for each player.

    Args:
        df: Pandas DataFrame with player_key, date, start_date, end_date and metric columns.
        player_key_col: Name of the player key column.
        date_col: Name of the date column.
        start_date_col: Name of the column with the start date.
        end_date_col: Name of the column with the end date.
        metrics: List of metric column names to calculate cumulative sums for.
                 If None, defaults to all numeric columns except player_key, date, start_date and end_date.

    Returns:
        Pandas DataFrame with added cumulative metric columns.
        Returns the original DataFrame if any error occurs.
    """

    try:
        df = df.sort_values([key_col, date_col])
        for metric in metrics:
            df[f'cumulative_{metric}'] = df.groupby(key_col)[metric].cumsum()

        return df  # Do NOT drop start_date and end_date

    except (KeyError, TypeError) as e:
        print(f"Error creating cumulative features: {e}")
        return df


metrics_cols = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
 "time_between_interactions",
    ]
df = calculate_cumulative_metrics(
    df, key_col="player_key", date_col="date", metrics=metrics_cols
)
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)



import pandas as pd
import numpy as np

def compute_per_day_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """Computes per-day metrics, handling division by zero.

    Args:
        df (pd.DataFrame): Input DataFrame containing cumulative metrics.

    Returns:
        pd.DataFrame: DataFrame with new per-day metric columns.
    """

    cumulative_columns = [col for col in df.columns if "cumulative_" in col and col != "cumulative_time_between_interactions"]

    for col in cumulative_columns:
        new_col_name = col.replace("cumulative_", "") + "_per_day"

        df[new_col_name] = np.where(df["cumulative_time_between_interactions"] == 0, 0, (df[col] / df["cumulative_time_between_interactions"]).round(4))


    return df


df = compute_per_day_metrics(df) # calculate the average of the metrics per day at each time point
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)



# craete date features
def create_date_features(df: pd.DataFrame, date_column: str) -> pd.DataFrame:
    """
    Extracts day of the week and month from a date column, and applies one-hot encoding.

    Args:
        df (pd.DataFrame): Input DataFrame with a date column.
        date_column (str): The name of the date column.

    Returns:
        pd.DataFrame: DataFrame with new one-hot encoded features.
    """
    # Ensure the date column is in datetime format
    df[date_column] = pd.to_datetime(df[date_column])

    # Extract day of the week and month as categorical
    df['day_of_week'] = df[date_column].dt.strftime('%A')  # Monday, Tuesday, etc.
    df['month'] = df[date_column].dt.strftime('%B')  # January, February, etc.
    df['year'] = df[date_column].dt.year.astype(str)  # Convert year to string for encoding

    # One-hot encode day_of_week, month, and year
    df = pd.get_dummies(df, columns=['day_of_week', 'month', 'year'], prefix=['day', 'month', 'year'])
    # Convert only dummy variables to float (excluding the date column)
    dummy_columns = [col for col in df.columns if col.startswith(('day_', 'month_', 'year_'))]
    df[dummy_columns] = df[dummy_columns].astype(float)

    return df


df = create_date_features(df, date_column="date")
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)






import pandas as pd

def days_since_last_positive_metrics(df: pd.DataFrame, date_col: str, player_col: str, metrics: list) -> pd.DataFrame:
    """
    Computes the number of days since the last positive value of each metric for each player.
    This function calculates it for all data points per player.

    Args:
        df (pd.DataFrame): Input DataFrame with time series data.
        date_col (str): The name of the datetime column.
        player_col (str): The column representing unique players.
        metrics (list): List of metric columns to check for positive values.

    Returns:
        pd.DataFrame: DataFrame with new columns 'days_since_last_positive_<metric>' for each metric.
    """
    # Ensure the date column is in datetime format
    df[date_col] = pd.to_datetime(df[date_col])

    # Sort by player and date to ensure correct calculations
    df = df.sort_values(by=[player_col, date_col])

    # Initialize new columns for each metric
    for metric in metrics:
        df[f'days_since_last_positive_{metric}'] = -1  # Default value

        # Iterate over each player separately
        for player in df[player_col].unique():
            player_data = df[df[player_col] == player]
            
            # Track last positive date for the metric
            last_positive_date = None

            for idx, row in player_data.iterrows():
                if row[metric] > 0:
                    last_positive_date = row[date_col]  # Update last positive date
                elif last_positive_date is not None:
                    df.at[idx, f'days_since_last_positive_{metric}'] = (row[date_col] - last_positive_date).days

    return df




metrics_cols = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
]
df = days_since_last_positive_metrics(df, 'date', 'player_key', metrics_cols) # Computes the number of days since the last positive value of each metric for each player.
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)






def create_metric_ratios(df: pd.DataFrame, ratio_pairs: list) -> pd.DataFrame:
    """Computes ratio features for given metric pairs, handling division by zero and NaNs.

    Args:
        df (pd.DataFrame): The input DataFrame with metric data.
        ratio_pairs (list): A list of tuples specifying (numerator, denominator) metric pairs.

    Returns:
        pd.DataFrame: DataFrame with new ratio columns.
    """
    for num, denom in ratio_pairs:
        ratio_col = f'ratio_{num}_to_{denom}'
        df[ratio_col] = df[num] / df[denom]

        # Handle division by zero and Infs (more robust)
        df[ratio_col] = df[ratio_col].replace([float('inf'), -float('inf')], pd.NA)  # Use pd.NA for missing values

        #Option 1: Preferred. Convert to numeric first before fillingna.
        df[ratio_col] = pd.to_numeric(df[ratio_col], errors='coerce').fillna(0)

        #Option 2: Fillna and then convert to numeric
        # df[ratio_col] = df[ratio_col].fillna(0) # Fill with 0
        # df[ratio_col] = pd.to_numeric(df[ratio_col], errors='coerce')  # Convert to numeric (important!)

    return df


metric_ratios = [
    ('turnover_sum', 'turnover_num'),
    ('NGR_sum', 'turnover_sum'),
    ('deposit_sum', 'withdrawal_sum')
]

df = create_metric_ratios(df, metric_ratios)
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)






def min_max_until_date(df: pd.DataFrame, date_col: str, player_col: str, metrics: list) -> pd.DataFrame:
    """
    Computes the minimum and maximum values of each metric until that date per player.

    Args:
        df (pd.DataFrame): Input DataFrame with time series data.
        date_col (str): The name of the datetime column.
        player_col (str): The column representing unique players.
        metrics (list): List of metric columns.

    Returns:
        pd.DataFrame: DataFrame with new columns for min and max values until that date.
    """
    # Ensure the date column is in datetime format
    df[date_col] = pd.to_datetime(df[date_col])

    # Sort by player and date to ensure correct calculations
    df = df.sort_values(by=[player_col, date_col])

    # Compute rolling min and max for each metric
    for metric in metrics:
        df[f'min_until_{metric}'] = df.groupby(player_col)[metric].expanding().min().reset_index(level=0, drop=True)
        df[f'max_until_{metric}'] = df.groupby(player_col)[metric].expanding().max().reset_index(level=0, drop=True)

    return df


metrics_cols = [
    "turnover_sum",
    "turnover_num",
    "NGR_sum",
    "deposit_sum",
    "deposit_num",
    "withdrawal_sum",
    "withdrawal_num",
    "login_num",
]
df = min_max_until_date(df, 'date', 'player_key', metrics_cols)
print_df_characteristics(df, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df)






joblib.dump(df, "./data/processed/features.pkl")





# Define the columns for outlier detection
columns_to_check = ['player_key', 'birth_year', 'date', 'turnover_sum', 'turnover_num',
       'NGR_sum', 'deposit_sum', 'deposit_num', 'withdrawal_sum',
       'withdrawal_num', 'login_num', 'age', 'row_number', 'max_row_number',
       'start_date', 'end_date', 'min_date', 'max_date', 'duration_all',
       'duration_spot', 'churn', 'player_key_backup',
       'time_between_interactions', 'cumulative_turnover_sum',
       'cumulative_turnover_num', 'cumulative_NGR_sum',
       'cumulative_deposit_sum', 'cumulative_deposit_num',
       'cumulative_withdrawal_sum', 'cumulative_withdrawal_num',
       'cumulative_login_num', 'cumulative_time_between_interactions',
       'turnover_sum_per_day', 'turnover_num_per_day', 'NGR_sum_per_day',
       'deposit_sum_per_day', 'deposit_num_per_day', 'withdrawal_sum_per_day',
       'withdrawal_num_per_day', 'login_num_per_day', 'day_Friday',
       'day_Monday', 'day_Saturday', 'day_Sunday', 'day_Thursday',
       'day_Tuesday', 'day_Wednesday', 'month_April', 'month_August',
       'month_December', 'month_February', 'month_January', 'month_July',
       'month_June', 'month_March', 'month_May', 'month_November',
       'month_October', 'month_September', 'year_2020', 'year_2021',
       'year_2022', 'year_2023', 'days_since_last_positive_turnover_sum',
       'days_since_last_positive_turnover_num',
       'days_since_last_positive_NGR_sum',
       'days_since_last_positive_deposit_sum',
       'days_since_last_positive_deposit_num',
       'days_since_last_positive_withdrawal_sum',
       'days_since_last_positive_withdrawal_num',
       'days_since_last_positive_login_num',
       'ratio_turnover_sum_to_turnover_num', 'ratio_NGR_sum_to_turnover_sum',
       'ratio_deposit_sum_to_withdrawal_sum', 'min_until_turnover_sum',
       'max_until_turnover_sum', 'min_until_turnover_num',
       'max_until_turnover_num', 'min_until_NGR_sum', 'max_until_NGR_sum',
       'min_until_deposit_sum', 'max_until_deposit_sum',
       'min_until_deposit_num', 'max_until_deposit_num',
       'min_until_withdrawal_sum', 'max_until_withdrawal_sum',
       'min_until_withdrawal_num', 'max_until_withdrawal_num',
       'min_until_login_num', 'max_until_login_num']
EDA(df, columns_to_check)








df_train = joblib.load("./data/processed/features.pkl")






def keep_numeric_and_convert_to_float(df: pd.DataFrame) -> pd.DataFrame:
    """
    Removes all columns that are dates and strings, keeping only numeric columns.
    Converts all integer columns to float.

    Args:
        df (pd.DataFrame): Input DataFrame.

    Returns:
        pd.DataFrame: DataFrame with only numeric columns (floats).
    """
    # Select only numeric columns (float, int)
    numeric_df = df.select_dtypes(include=['number']).copy()

    # Convert integer columns to float
    for col in numeric_df.columns:
        if pd.api.types.is_integer_dtype(numeric_df[col]):
            numeric_df[col] = numeric_df[col].astype('float64')

    return numeric_df


df_train = keep_numeric_and_convert_to_float(df_train)
df_train = df_train.drop(columns=["player_key_small","player_key_backup", "birth_year", "duration_all"], errors='ignore')
print_df_characteristics(df_train, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df_train)



def find_non_float_columns(df: pd.DataFrame) -> list:
    """Finds and prints columns in a DataFrame that are not of float dtype.

    Args:
        df: The input Pandas DataFrame.

    Returns:
        A list of column names that are not float type.
        Prints a message indicating whether any non-float columns were found.
    """
    non_float_cols = []
    for col in df.columns:
        if df[col].dtype != float:  # Direct type comparison
            non_float_cols.append(col)

    if non_float_cols:
        print("Columns that are NOT float type:")
        for col in non_float_cols:
            print(f"- {col}: {df[col].dtype}")  # Print column name and dtype
    else:
        print("All columns are of float type.")

    return non_float_cols


non_float_columns2 = find_non_float_columns(df_train)
print_df_characteristics(df_train, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df_train)



def prepare_dataframe(df: pd.DataFrame, player_col: str = 'player_key', time_col: str = 'row_number') -> pd.DataFrame:
    """
    Moves 'player_key' to index and sorts the DataFrame by 'player_key' and 'row_number'.

    Args:
        df (pd.DataFrame): Input DataFrame.
        player_col (str): Name of the player key column.
        time_col (str): Name of the time column for sorting.

    Returns:
        pd.DataFrame: Processed DataFrame with 'player_key' as index and sorted.
    """
    # Move player_key to index if it's not already
    if player_col in df.columns:
        df = df.set_index(player_col)
    
    # Ensure DataFrame is sorted by index and row_number
    df = df.sort_values(by=[df.index.name, time_col])

    return df


df_train = prepare_dataframe(df_train)
print_df_characteristics(df_train, print_=print_df_chars)
nan_cols, inf_cols, combined_cols, original_df = check_and_identify_problematic_columns(df_train)








from sklearn.model_selection import BaseCrossValidator

class GroupTimeSeriesSplit(BaseCrossValidator):
    """
    Custom Group-Based Time Series Split ensuring:
    - Each fold uses **future** observations for validation.
    - Players **do not mix** between train & test.
    - Data leakage is prevented.
    """

    def __init__(self, n_splits=3):
        self.n_splits = n_splits

    def split(self, X, y=None, groups=None):
        unique_players = np.unique(groups)
        n_players = len(unique_players)
        fold_size = n_players // (self.n_splits + 1)

        for i in range(self.n_splits):
            train_players = unique_players[:fold_size * (i+1)]
            test_players = unique_players[fold_size * (i+1): fold_size * (i+2)]

            train_idx = X.index[X.index.isin(train_players)]
            test_idx = X.index[X.index.isin(test_players)]

            yield train_idx, test_idx

    def get_n_splits(self, X, y, groups):
        return self.n_splits






from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score

# Define Features & Target Before Sorting
X = df_train.drop(columns=['churn'])  # Extract Features
y = df_train['churn']  # Extract Target

# Ensure X and y Indices Match
X, y = X.align(y, join='inner', axis=0)

# ‚úÖ Debug the correct size
print(f"After Alignment - X shape: {X.shape}, y shape: {y.shape}")
#  Sort the Data (AFTER defining X and y)
X = X.sort_values(by=['player_key', 'row_number'])
y = y.reindex(X.index)  # Use `reindex()` instead of `loc` to prevent misalignment

# Convert Index to Integer
X.index = X.index.astype(int)
groups = np.array(X.index)  # Use player_key as groups
# Debugging Output
print(f"‚úÖ X shape: {X.shape}, y shape: {y.shape}, groups shape: {len(groups)}")








import lightgbm as lgb

# ‚úÖ Optimized LightGBM Model
lgbm_model = lgb.LGBMClassifier(
    random_state=42,
    boosting_type='gbdt',
    objective='binary',
    class_weight='balanced',
    n_jobs=-1,  # Use all CPU cores
    force_row_wise=True,  # Optimized for memory
    verbosity=-1  # Suppress logs
)

# ‚úÖ New Hyperparameter Grid (More Variability)
param_grid = {
    'n_estimators': [50, 100, 200],  # More trees for better learning
    'learning_rate': [0.005, 0.01, 0.05],  # Lower LR to prevent overfitting
    'num_leaves': [31, 63, 127],  # More leaves = more complexity
    'max_depth': [5, 10, 15],  # Prevent overfitting
    'min_child_samples': [5, 10, 20],  # Lower min_child_samples
    'subsample': [0.6, 0.8, 1.0],  # Higher sampling rate
    'colsample_bytree': [0.6, 0.8, 1.0],  # More feature sampling
    'reg_alpha': [0, 0.1, 0.5],  # L1 Regularization (Prevents overfitting)
    'reg_lambda': [0.1, 0.5, 1.0]  # L2 Regularization
}


# Apply Group-Based Time Series Split
cv = GroupTimeSeriesSplit(n_splits=3)

# Debug: Verify split works
for i, (train_idx, test_idx) in enumerate(cv.split(X, y, groups)):
    X_train, X_test = X.loc[train_idx], X.loc[test_idx]

    print(f"\nüîπ Fold {i+1}")
    print(f"Train size={len(train_idx)}, Test size={len(test_idx)}")

    # Print unique player_keys at the start and end of train and test sets
    print(f"Train Player Keys: Start={X_train.index.min()}, End={X_train.index.max()}")
    print(f"Test Player Keys: Start={X_test.index.min()}, End={X_test.index.max()}")

    # Print time range (row_number) of train and test sets
    print(f"Train Data Time Range: Start={X_train['row_number'].min()}, End={X_train['row_number'].max()}")
    print(f"Test Data Time Range: Start={X_test['row_number'].min()}, End={X_test['row_number'].max()}")

    # Ensure no overlap between train and test sets
    overlapping_players = set(X_train.index) & set(X_test.index)
    print(f"‚ö†Ô∏è Overlapping Players: {len(overlapping_players)} (Should be 0)")


# Run GridSearchCV WITHOUT callback (fixing pickling error)
grid_search = GridSearchCV(
    lgbm_model, param_grid, 
    cv=cv.split(X, y, groups=groups), 
    scoring='f1', verbose=0, n_jobs=4  # Reduce parallel jobs to prevent crashes
)

grid_search.fit(X, y)  # Do not use `callback=update_progress`

# Fit the model
#grid_search.fit(X, y)

# Get best model
best_rf = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)














from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, log_loss, 
    matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score
)

# Correct way: Only evaluate on the last test set
for train_idx, test_idx in cv.split(X, y, groups):
    X_train, X_test = X.loc[train_idx], X.loc[test_idx]
    y_train, y_test = y.loc[train_idx], y.loc[test_idx]

# Fit best model on last train set and evaluate on last test set
best_rf.fit(X_train, y_train)
y_pred = best_rf.predict(X_test)
y_pred_proba = best_rf.predict_proba(X_test)[:, 1]

# Compute Metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Additional Metrics
roc_auc = roc_auc_score(y_test, y_pred_proba)  # AUC-ROC Score (Probability-based)
pr_auc = average_precision_score(y_test, y_pred_proba)  # Precision-Recall AUC
log_loss_score = log_loss(y_test, y_pred_proba)  # Log Loss (Good for probability calibration)
mcc = matthews_corrcoef(y_test, y_pred)  # MCC (Balances all confusion matrix components)
cohen_kappa = cohen_kappa_score(y_test, y_pred)  # Cohen‚Äôs Kappa (Measures agreement)
balanced_acc = balanced_accuracy_score(y_test, y_pred)  # Adjusted for class imbalance

# Print Results
print("\nüîπ Final Model Evaluation on Test Set üîπ")
print(f"Accuracy: {accuracy:.4f}")
print(f"Balanced Accuracy: {balanced_acc:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall (Sensitivity): {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"AUC-ROC Score: {roc_auc:.4f}")
print(f"PR-AUC Score: {pr_auc:.4f}")
print(f"Log Loss: {log_loss_score:.4f}")
print(f"Matthews Correlation Coefficient (MCC): {mcc:.4f}")
print(f"Cohen's Kappa: {cohen_kappa:.4f}")








from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
performance_plots_united(X, y, y_pred,  y_pred_proba, best_rf)








import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
from sklearn.model_selection import learning_curve

# ‚úÖ 1Ô∏è‚É£ Confusion Matrix
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

# ‚úÖ 2Ô∏è‚É£ ROC-AUC Curve
def plot_roc_curve(y_true, y_proba):
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-AUC Curve")
    plt.legend()
    plt.show()

# ‚úÖ 3Ô∏è‚É£ Precision-Recall Curve
def plot_precision_recall_curve(y_true, y_proba):
    precision, recall, _ = precision_recall_curve(y_true, y_proba)
    plt.figure(figsize=(6, 5))
    plt.plot(recall, precision, label="Precision-Recall Curve", color="green")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve")
    plt.legend()
    plt.show()

# ‚úÖ 4Ô∏è‚É£ Feature Importance
def plot_feature_importance(model, feature_names):
    importance = model.feature_importances_
    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

    plt.figure(figsize=(8, 5))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
    plt.title("Feature Importance")
    plt.xlabel("Importance Score")
    plt.ylabel("Feature")
    plt.show()

# ‚úÖ 5Ô∏è‚É£ Learning Curve
def plot_learning_curve(model, X, y):
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=3, scoring='f1', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)
    )
    train_mean, train_std = np.mean(train_scores, axis=1), np.std(train_scores, axis=1)
    test_mean, test_std = np.mean(test_scores, axis=1), np.std(test_scores, axis=1)

    plt.figure(figsize=(8, 5))
    plt.plot(train_sizes, train_mean, label="Training Score", color='blue')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
    plt.plot(train_sizes, test_mean, label="Cross-Validation Score", color='red')
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)

    plt.xlabel("Training Sample Size")
    plt.ylabel("F1 Score")
    plt.title("Learning Curve")
    plt.legend()
    plt.show()

# ‚úÖ 6Ô∏è‚É£ Performance Plots (Final Fix)
def performance_plots_united(X, y, y_pred, y_pred_proba, best_rf):
    """
    Generates all performance plots:
    - Confusion Matrix
    - ROC Curve
    - Precision-Recall Curve
    - Feature Importance
    - Learning Curve
    """

    # üîπ Ensure `y_pred` matches `y`
    print(f"DEBUG: y.shape={y.shape}, y_pred.shape={y_pred.shape}, y_pred_proba.shape={y_pred_proba.shape}")

    # ‚úÖ Generate Plots
    plot_confusion_matrix(y, y_pred)
    plot_roc_curve(y, y_pred_proba)
    plot_precision_recall_curve(y, y_pred_proba)
    plot_feature_importance(best_rf, X.columns)
    plot_learning_curve(best_rf, X, y)



y_pred_proba = best_rf.predict_proba(X)[:, 1]
y_pred = (y_pred_proba > 0.5).astype(int)  # Convert to binary

performance_plots_united(X, y, y_pred, y_pred_proba, best_rf)






# ========== Generate Performance Plots ==========

# 5.1 Confusion Matrix
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()


# 5.2 ROC-AUC Curve
def plot_roc_curve(y_true, y_proba):
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-AUC Curve")
    plt.legend()
    plt.show()


# 5.3 Precision-Recall Curve
def plot_precision_recall_curve(y_true, y_proba):
    precision, recall, _ = precision_recall_curve(y_true, y_proba)
    plt.figure(figsize=(6, 5))
    plt.plot(recall, precision, label="Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve")
    plt.legend()
    plt.show()


# 5.4 Feature Importance
def plot_feature_importance(model, feature_names):
    importance = model.feature_importances_
    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
    
    plt.figure(figsize=(8, 5))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
    plt.title("Feature Importance")
    plt.xlabel("Importance Score")
    plt.ylabel("Feature")
    plt.show()


# 5.5 Learning Curve
from sklearn.model_selection import learning_curve

def plot_learning_curve(model, X, y):
    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=3, scoring='f1', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))
    train_mean, train_std = np.mean(train_scores, axis=1), np.std(train_scores, axis=1)
    test_mean, test_std = np.mean(test_scores, axis=1), np.std(test_scores, axis=1)

    plt.figure(figsize=(8, 5))
    plt.plot(train_sizes, train_mean, label="Training Score", color='blue')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
    plt.plot(train_sizes, test_mean, label="Cross-Validation Score", color='red')
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)
    
    plt.xlabel("Training Sample Size")
    plt.ylabel("F1 Score")
    plt.title("Learning Curve")
    plt.legend()
    plt.show()


def performance_plots_united(X, y, y_pred,  y_pred_proba, best_rf):
    plot_confusion_matrix(y, y_pred)
    plot_roc_curve(y, y_pred_proba)
    plot_precision_recall_curve(y, y_pred_proba)
    plot_feature_importance(best_rf, X.columns)
    plot_learning_curve(best_rf, X, y)


performance_plots_united(X, y, y_pred,  y_pred_proba, best_rf)

















import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    confusion_matrix, roc_curve, auc, precision_recall_curve, 
    accuracy_score, precision_score, recall_score, f1_score
)
from sklearn.utils import shuffle

def time_series_cv(df, date_col, player_col, n_splits=3):
    """
    Performs time-aware cross-validation for churn prediction.
    
    Args:
        df (pd.DataFrame): Input DataFrame with time-ordered player data.
        date_col (str): Column representing time (row_number or date).
        player_col (str): Column representing unique players.
        n_splits (int): Number of CV folds.
    
    Returns:
        List of train-test index splits.
    """
    df = df.sort_values(by=[player_col, date_col])  # Ensure time ordering

    tscv = TimeSeriesSplit(n_splits=n_splits)
    features = df.drop(columns=[player_col, 'churn'])

    return [(train_idx, test_idx) for train_idx, test_idx in tscv.split(features)]


# Train-Test Split (Time-Based)
cv_splits = time_series_cv(df_train, 'row_number', 'player_key', n_splits=3)

# Features & Target
X = df_train.drop(columns=['player_key', 'churn'])  # Features
y = df_train['churn']  # Target


# Define Random Forest Model
rf_model = RandomForestClassifier(random_state=42)

# Define Hyperparameter Grid
param_grid = {
    'n_estimators': [50],
    'max_depth': [5, 10],
    # 'min_samples_split': [2, 5, 10],
    # 'min_samples_leaf': [1, 2, 5]
}

# Run GridSearchCV with Time Series CV
grid_search = GridSearchCV(
    rf_model, 
    param_grid, 
    cv=cv_splits, 
    scoring='f1', 
    n_jobs=2, 
    verbose=1
)
grid_search.fit(X, y)
# grid_search.fit(X, y)






import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    confusion_matrix, roc_curve, auc, precision_recall_curve, 
    accuracy_score, precision_score, recall_score, f1_score
)
from sklearn.utils import shuffle

def time_series_cv(df, date_col, player_col, n_splits=3):
    """
    Performs time-aware cross-validation for churn prediction.
    
    Args:
        df (pd.DataFrame): Input DataFrame with time-ordered player data.
        date_col (str): Column representing time (row_number or date).
        player_col (str): Column representing unique players.
        n_splits (int): Number of CV folds.
    
    Returns:
        List of train-test index splits.
    """
    df = df.sort_values(by=[player_col, date_col])  # Ensure time ordering

    tscv = TimeSeriesSplit(n_splits=n_splits)
    features = df.drop(columns=[player_col, 'churn'])

    return [(train_idx, test_idx) for train_idx, test_idx in tscv.split(features)]


# Train-Test Split (Time-Based)
cv_splits = time_series_cv(df_numeric, 'row_number', 'player_key', n_splits=3)

# Features & Target
X = df_numeric.drop(columns=['player_key', 'churn'])  # Features
y = df_numeric['churn']  # Target

# Define Random Forest Model
rf_model = RandomForestClassifier(random_state=42)

# Define Hyperparameter Grid
param_grid = {
    'n_estimators': [10, 20, 30],
    'max_depth': [5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}

# Run GridSearchCV with Time Series CV
grid_search = GridSearchCV(
    rf_model, 
    param_grid, 
    cv=cv_splits, 
    scoring='f1', 
    n_jobs=2, 
    verbose=1
)


grid_search.fit(X, y)
best_rf = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# ========== 4Ô∏è‚É£ Evaluate Model ==========
y_pred = best_rf.predict(X)
y_pred_proba = best_rf.predict_proba(X)[:, 1]

accuracy = accuracy_score(y, y_pred)
precision = precision_score(y, y_pred)
recall = recall_score(y, y_pred)
f1 = f1_score(y, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# ========== 5Ô∏è‚É£ Generate Performance Plots ==========

# 5.1 Confusion Matrix
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

plot_confusion_matrix(y, y_pred)

# 5.2 ROC-AUC Curve
def plot_roc_curve(y_true, y_proba):
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-AUC Curve")
    plt.legend()
    plt.show()

plot_roc_curve(y, y_pred_proba)

# 5.3 Precision-Recall Curve
def plot_precision_recall_curve(y_true, y_proba):
    precision, recall, _ = precision_recall_curve(y_true, y_proba)
    plt.figure(figsize=(6, 5))
    plt.plot(recall, precision, label="Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve")
    plt.legend()
    plt.show()

plot_precision_recall_curve(y, y_pred_proba)

# 5.4 Feature Importance
def plot_feature_importance(model, feature_names):
    importance = model.feature_importances_
    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
    
    plt.figure(figsize=(8, 5))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
    plt.title("Feature Importance")
    plt.xlabel("Importance Score")
    plt.ylabel("Feature")
    plt.show()

plot_feature_importance(best_rf, X.columns)

# 5.5 Learning Curve
from sklearn.model_selection import learning_curve

def plot_learning_curve(model, X, y):
    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=3, scoring='f1', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))
    train_mean, train_std = np.mean(train_scores, axis=1), np.std(train_scores, axis=1)
    test_mean, test_std = np.mean(test_scores, axis=1), np.std(test_scores, axis=1)

    plt.figure(figsize=(8, 5))
    plt.plot(train_sizes, train_mean, label="Training Score", color='blue')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
    plt.plot(train_sizes, test_mean, label="Cross-Validation Score", color='red')
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)
    
    plt.xlabel("Training Sample Size")
    plt.ylabel("F1 Score")
    plt.title("Learning Curve")
    plt.legend()
    plt.show()

plot_learning_curve(best_rf, X, y)










