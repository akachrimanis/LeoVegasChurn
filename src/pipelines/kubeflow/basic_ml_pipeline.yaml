# PIPELINE DEFINITION
# Name: basic-ml-pipeline
# Description: A basic example of a Kubeflow Pipeline for ML.
# Inputs:
#    data_path: str [Default: '/Users/tkax/dev/aimonetize/WIP/AIAgents/src/data/kubeflow_data.csv']
components:
  comp-data-prep-op:
    executorLabel: exec-data-prep-op
    inputDefinitions:
      parameters:
        input_path:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-etl-op:
    executorLabel: exec-etl-op
    inputDefinitions:
      parameters:
        data_path:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-evaluate-model-op:
    executorLabel: exec-evaluate-model-op
    inputDefinitions:
      parameters:
        input_path:
          parameterType: STRING
        model_path:
          parameterType: STRING
  comp-feature-engineering-op:
    executorLabel: exec-feature-engineering-op
    inputDefinitions:
      parameters:
        input_path:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-train-model-op:
    executorLabel: exec-train-model-op
    inputDefinitions:
      parameters:
        input_path:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-data-prep-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_prep_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_prep_op(input_path: str) -> str:\n    \"\"\"Data preparation\
          \ component: Cleans and preprocesses the data.\"\"\"\n    import pandas\
          \ as pd\n    output_path = \"prep_data.parquet\"\n    df = pd.read_parquet(input_path)\n\
          \    # Basic data cleaning/preprocessing (example)\n    df = df.dropna()\
          \  # Drop rows with missing values\n    df = df.fillna(0)\n    df.to_parquet(output_path)\n\
          \    print(f\"Data preparation completed. Data saved to {output_path}\"\
          )\n    return output_path\n\n"
        image: python:3.10
    exec-etl-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - etl_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef etl_op(data_path: str) -> str:\n    \"\"\"ETL component: Reads\
          \ data from a CSV and saves it as Parquet.\"\"\"\n    import pandas as pd\n\
          \    import os\n    output_path = \"etl_data.parquet\"\n    df = pd.read_csv(data_path)\n\
          \    df.to_parquet(output_path)\n    print(f\"ETL completed. Data saved\
          \ to {output_path}\")\n    return output_path\n\n"
        image: python:3.10
    exec-evaluate-model-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model_op(model_path: str, input_path: str):\n    \"\"\
          \"Model evaluation component: Evaluates the trained model.\"\"\"\n    import\
          \ pandas as pd\n    from sklearn.metrics import mean_squared_error\n   \
          \ import joblib\n    import mlflow\n\n    with mlflow.start_run() as run:\n\
          \        model = joblib.load(model_path)\n        df = pd.read_parquet(input_path)\n\
          \        X = df.drop(columns=df.columns[-1])\n        y = df.iloc[:,-1]\n\
          \        y_pred = model.predict(X)\n        mse = mean_squared_error(y,\
          \ y_pred)\n        mlflow.log_metric(\"mse\", mse)\n        print(f\"Model\
          \ evaluation completed. MSE: {mse}\")\n\n"
        image: python:3.10
    exec-feature-engineering-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - feature_engineering_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef feature_engineering_op(input_path: str) -> str:\n    \"\"\"Feature\
          \ engineering component: Creates new features.\"\"\"\n    import pandas\
          \ as pd\n    output_path = \"feature_data.parquet\"\n    df = pd.read_parquet(input_path)\n\
          \    # Example feature engineering: Create a new feature\n    df[\"feature_1\"\
          ] = df.iloc[:,0] * 2 #example feature\n    df.to_parquet(output_path)\n\
          \    print(f\"Feature engineering completed. Data saved to {output_path}\"\
          )\n    return output_path\n\n"
        image: python:3.10
    exec-train-model-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model_op(input_path: str) -> str:\n    \"\"\"Model training\
          \ component: Trains a linear regression model.\"\"\"\n    import pandas\
          \ as pd\n    from sklearn.model_selection import train_test_split\n    from\
          \ sklearn.linear_model import LinearRegression\n    import joblib\n    import\
          \ mlflow\n    output_path = \"model.joblib\"\n\n    mlflow.set_tracking_uri(\"\
          http://127.0.0.1:5000\") #replace with your mlflow server url\n    with\
          \ mlflow.start_run() as run:\n        df = pd.read_parquet(input_path)\n\
          \        X = df.drop(columns=df.columns[-1])\n        y = df.iloc[:,-1]\n\
          \        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\
          \ random_state=42)\n\n        model = LinearRegression()\n        model.fit(X_train,\
          \ y_train)\n\n        joblib.dump(model, output_path)\n        mlflow.sklearn.log_model(sk_model=model,\
          \ artifact_path=\"model\")\n        print(f\"Model training completed. Model\
          \ saved to {output_path}\")\n    return output_path\n\n"
        image: python:3.10
pipelineInfo:
  description: A basic example of a Kubeflow Pipeline for ML.
  name: basic-ml-pipeline
root:
  dag:
    tasks:
      data-prep-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-prep-op
        dependentTasks:
        - etl-op
        inputs:
          parameters:
            input_path:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: etl-op
        taskInfo:
          name: data-prep-op
      etl-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-etl-op
        inputs:
          parameters:
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: etl-op
      evaluate-model-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model-op
        dependentTasks:
        - feature-engineering-op
        - train-model-op
        inputs:
          parameters:
            input_path:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: feature-engineering-op
            model_path:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model-op
        taskInfo:
          name: evaluate-model-op
      feature-engineering-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-feature-engineering-op
        dependentTasks:
        - data-prep-op
        inputs:
          parameters:
            input_path:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: data-prep-op
        taskInfo:
          name: feature-engineering-op
      train-model-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model-op
        dependentTasks:
        - feature-engineering-op
        inputs:
          parameters:
            input_path:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: feature-engineering-op
        taskInfo:
          name: train-model-op
  inputDefinitions:
    parameters:
      data_path:
        defaultValue: /Users/tkax/dev/aimonetize/WIP/AIAgents/src/data/kubeflow_data.csv
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
